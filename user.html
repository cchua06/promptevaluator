<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GenAI Prompt Feedback POC</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
    <style>
      body { @apply bg-gray-50 text-gray-800; font-family: 'Inter', sans-serif; }
      textarea { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
      .fade-in { animation: fade-in 0.3s ease-out; }
      @keyframes fade-in { from { opacity:0; transform: translateY(4px);} to { opacity:1; transform: translateY(0);} }
      h1, h2, h3, h4, h5, h6, .font-bold, .font-semibold, .text-3xl, .text-4xl, .font-bold, .font-semibold {
        font-family: 'Inter', sans-serif;
        font-weight: 600;
      }
    </style>
  </head>
  <body class="min-h-screen flex flex-col">
    <div id="root" class="flex-1"></div>

    <script type="text/babel">
      // ---------------------------
      // OpenAI Evaluator Function
      // ---------------------------

      async function evaluatePrompt(prompt) {
        // System instructions for the evaluator
        const systemInstructions = `
SYSTEM PROMPT: Friendly Prompt Structure Reviewer

You are a prompt-structure reviewer. Your job is to check whether a userâ€™s prompt contains the four key building blocks of a well-structured prompt:

Task â€“ a clear action, defined deliverable, and intended audience.

Input â€“ the raw materials, context, or data sources the AI should rely on.

Steps â€“ a logically ordered process the AI should follow. This could be a numbered list, a bulleted list, or clearly sequenced instructions written in paragraph form.

Output â€“ formatting, tone, and structural expectations for the final answer.

How to evaluate

Read the prompt carefully.

For each of the four components, decide whether it is Present or Missing.

Mark an element â€œMissingâ€ only if it is truly absent or so vague that it cannot guide the AI.

If an element could be clearer but is still serviceable, consider it Present and save suggestions for the â€œImprovementsâ€ line.

Keep the assessment encouraging and focused on major gaps, not minor wording tweaks.

Output format

If any component is Missing:

Letâ€™s enhance this! ðŸ§“

Missing components: [List any of: Task, Input, Steps, Output]

Improvements suggested for: [List any elements that are present but could be clearer]

Breakdown:
Task: [Brief note if missing or how it could be clarified]
Input: [Brief note if missing or how it could be clarified]
Steps: [Brief note if missing or how it could be clarified]
Output: [Brief note if missing or how it could be clarified]

If all four components are Present:

Amazing job! ðŸŽ‰

All four components are clearly present!

Highlights: [E.g. â€œwell-scoped inputsâ€, â€œaction-oriented stepsâ€, â€œprecise output formattingâ€]

ðŸ”š Evaluation criteria recap:
Task â€“ Starts with a verb, states deliverable & audience
Input â€“ Specific, bounded data/context
Steps â€“ Logically ordered instructions using numbers, bullets, or paragraph sequencing
Output â€“ Clear tone, length, and formatting guidance

Style guidelines

Do NOT rewrite or suggest an improved prompt.

Do NOT ask the user follow-up questions.

Do NOT end with extra guidance or speculative improvements beyond the required lines.

Keep feedback conciseâ€”focus only on what matters for prompt structure.
        `;

        try {
          const res = await fetch('/api/evaluate', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt, systemInstructions })
          });
          console.log(prompt, systemInstructions)
          if (!res.ok) {
            throw new Error(`API error: ${res.status} ${res.statusText}`);
          }
          const data = await res.json();
          return { notes: data.notes };
        } catch (err) {
          console.error('Error evaluating prompt:', err);
          return { notes: 'There was an error contacting the evaluation service.' };
        }
      }

      const isBlank = (s) => !s || s.trim().length === 0;
      // Call backend to generate Facilitator Feedback using OpenAI GPT-4o
      const generateFacilitatorFeedback = async (prompt, evaluation) => {
        const formattedInput = `Prompt:\n${prompt}\n\nEvaluation:\n${evaluation}`;
        const systemInstructions = `
Your task is to generate structured support content to help the facilitator guide the participant toward a better prompt.

Inputs:
Prompt:
<prompt>

Evaluation:
<evaluation>

Your output must follow this format:

Task Summary:

Summarize what the participant is trying to achieve based on their prompt. Use the evaluation only to clarify whatâ€™s missing or weakâ€”donâ€™t just restate it. Write 1â€“2 objective sentences. If the task is unclear, say so.

Guidance:

Write 2â€“5 bullet points that provide facilitator-facing guidance. These should be confident, actionable suggestionsâ€”not questions. Focus on moving the participant forward based on whatâ€™s wrong, as indicated in the evaluation. Avoid direct criticism or prompt rewrites.

Be use-case specific when possible: e.g., suggest uploading a file, clarifying audience, giving example inputs, or breaking the task into steps.
        `;

        try {
          const res = await fetch('/api/facilitator-feedback', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt, systemInstructions })
          });
          if (!res.ok) {
            throw new Error(`API error: ${res.status} ${res.statusText}`);
          }
          const data = await res.json();
          return data.feedback || '';
        } catch (err) {
          console.error('Error generating Facilitator Feedback:', err);
          return 'There was an error generating the facilitator feedback.';
        }
      };

      const sendToEvaluator = async ({ prompt }) => {
        const evaluationFeedback = await evaluatePrompt(prompt);
        const { notes } = evaluationFeedback;
        const facilitatorFeedback = await generateFacilitatorFeedback(prompt, evaluationFeedback.notes);
        return { notes, facilitatorFeedback };
      };


      // ---------------------------
      // Storage Toggle
      // ---------------------------
      let USE_LOCAL_STORAGE = false; // Will be set by backend

      const STORAGE_KEY = 'prompt_records_v1';

      function saveRecordLocal(rec) {
        const arr = JSON.parse(localStorage.getItem(STORAGE_KEY) || '[]');
        arr.unshift(rec);
        localStorage.setItem(STORAGE_KEY, JSON.stringify(arr));
      }
      function loadRecordsLocal() {
        try { return JSON.parse(localStorage.getItem(STORAGE_KEY) || '[]'); } catch { return []; }
      }

      // ---------------------------
      // React Component
      // ---------------------------
      function App() {
        const [firstName, setFirstName] = React.useState("");
        const [lastName,  setLastName]  = React.useState("");
        const [prompt,    setPrompt]    = React.useState("");
        const [records,   setRecords]   = React.useState([]);
        const [isSubmitting, setIsSubmitting] = React.useState(false);
        const [lastEval,  setLastEval]  = React.useState(null);
        // Facilitator Feedback is not shown to the user

        // On mount, get storage mode and load records if local
        React.useEffect(() => {
          fetch('/api/storage-mode').then(r => r.json()).then(({ useLocalStorage }) => {
            USE_LOCAL_STORAGE = useLocalStorage;
            if (USE_LOCAL_STORAGE) setRecords(loadRecordsLocal());
          });
        }, []);

        // For localStorage, keep in sync
        React.useEffect(() => {
          if (USE_LOCAL_STORAGE) localStorage.setItem(STORAGE_KEY, JSON.stringify(records));
        }, [records]);

        const handleSubmit = async (e) => {
          e.preventDefault();
          if (isBlank(firstName) || isBlank(lastName)) return alert("First and last name cannot be blank.");
          if (!prompt.trim()) return;
          setIsSubmitting(true);

          const { notes, facilitatorFeedback } = await sendToEvaluator({ prompt });
          const ts = new Date().toISOString();
          const newRec = {
            id: crypto.randomUUID(),
            timestamp: ts,
            firstname: firstName.trim(),
            lastname: lastName.trim(),
            prompt: prompt,
            notes: notes,
            facilitatorfeedback: facilitatorFeedback
          };
          if (USE_LOCAL_STORAGE) {
            saveRecordLocal(newRec);
            setRecords(prev => [newRec, ...prev]);
          } else {
            // Save to backend (now using prompts table in promptdb)
            try {
              await fetch('/api/record', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(newRec)
              });
            } catch (err) {
              alert('Failed to save record to server.');
            }
            setRecords(prev => [newRec, ...prev]);
          }
          setLastEval({ notes, ts });
          setPrompt(""); setFirstName(""); setLastName("");
          setIsSubmitting(false);
        };

        return (
          <div className="w-full pt-20 pb-12 px-4">
            <div className="flex items-start max-w-7xl mx-auto">
              <div className="flex-shrink-0 w-[160px] mr-8 flex justify-center">
                <img src="./resources/tm_logo.png" alt="Thinking Machines Logo" className="h-[160px] w-auto" />
              </div>

              <div className="flex-1 max-w-5xl mx-auto">
                <header className="mb-6 text-left">
                  <h1 className="text-4xl font-bold leading-tight mb-2">Thinking Machines Prompt Evaluator</h1>
                  <span className="text-sm text-gray-500 hidden sm:inline">Beta testing</span>
                  <p className="text-gray-600 mt-2">Quickly score &amp; review prompts during enablement sessions.</p>
                </header>

                <section className="mb-10">
                  <form onSubmit={handleSubmit} className="bg-white shadow rounded-lg p-10 space-y-8">
                    <div>
                      <label className="block text-sm font-medium mb-1">First Name <span className="text-red-600">*</span></label>
                      <input type="text" className="w-full border rounded px-5 py-3" value={firstName} onChange={e => setFirstName(e.target.value)} placeholder="e.g., Alice" required />
                    </div>
                    <div>
                      <label className="block text-sm font-medium mb-1">Last Name <span className="text-red-600">*</span></label>
                      <input type="text" className="w-full border rounded px-5 py-3" value={lastName} onChange={e => setLastName(e.target.value)} placeholder="e.g., Garcia" required />
                    </div>
                    <div>
                      <label className="block text-sm font-medium mb-1">Prompt <span className="text-red-600">*</span></label>
                      <textarea className="w-full border rounded px-5 py-3 h-40" value={prompt} onChange={e => setPrompt(e.target.value)} placeholder="Paste your prompt here to check against prompt writing best practices" required />
                    </div>
                    <div className="flex items-center gap-4">
                      <button type="submit" disabled={isSubmitting || !prompt.trim()} className={`px-7 py-3 rounded text-white ${isSubmitting || !prompt.trim() ? 'bg-gray-400 cursor-not-allowed' : 'bg-blue-600 hover:bg-blue-700'}`}>{isSubmitting ? 'Evaluatingâ€¦' : 'Submit'}</button>
                      <span className="ml-auto text-sm text-gray-500 hidden sm:inline">Stored locally for admin view</span>
                    </div>
                  </form>

                  {lastEval && (
                    <div className="mt-10 bg-white border-l-4 border-blue-500 shadow rounded-lg p-8 fade-in">
                      <h3 className="font-semibold mb-2 text-base">Evaluation Feedback <span className="text-gray-500">({new Date(lastEval.ts).toLocaleString()})</span></h3>
                      <p className="whitespace-pre-wrap break-words text-sm">{lastEval.notes}</p>
                    </div>
                  )}

                  {/* Facilitator Feedback is not shown to the user */}
                </section>

                <footer className="mt-20 text-xs text-gray-400 text-center">
                  <p>POC only â€“ using live OpenAI API evaluation. Store your API key securely.</p>
                </footer>
              </div>

              <div className="flex-shrink-0 w-[160px] ml-8"></div>
            </div>
          </div>
        );
      }

      ReactDOM.createRoot(document.getElementById('root')).render(<App />);
    </script>
  </body>
</html>
